{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>department</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>closing_date</th>\n",
       "      <th>uid</th>\n",
       "      <th>scraped_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst - Corporate Performance</td>\n",
       "      <td>Companies House</td>\n",
       "      <td>Cardiff, Wales, CF14 3UZ</td>\n",
       "      <td>46,588</td>\n",
       "      <td>2024-03-05</td>\n",
       "      <td>153376</td>\n",
       "      <td>2024-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kitchen Steward</td>\n",
       "      <td>House of Commons</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>24,959</td>\n",
       "      <td>2024-05-19</td>\n",
       "      <td>200324</td>\n",
       "      <td>2024-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>National Professional Advisor (for People with...</td>\n",
       "      <td>Care Quality Commission</td>\n",
       "      <td>East Midlands (England), East of England, Lond...</td>\n",
       "      <td>70,000</td>\n",
       "      <td>2024-02-26</td>\n",
       "      <td>24711</td>\n",
       "      <td>2024-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Commis Chef</td>\n",
       "      <td>House of Commons</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>24,959</td>\n",
       "      <td>2024-05-19</td>\n",
       "      <td>255755</td>\n",
       "      <td>2024-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Recreation Works Supervisor</td>\n",
       "      <td>Forestry Commission</td>\n",
       "      <td>Burley Office, Burley, Hampshire BH24 4HS</td>\n",
       "      <td>26,534</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>257501</td>\n",
       "      <td>2024-01-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title               department  \\\n",
       "0       Senior Data Analyst - Corporate Performance           Companies House   \n",
       "1                                    Kitchen Steward         House of Commons   \n",
       "2  National Professional Advisor (for People with...  Care Quality Commission   \n",
       "3                                        Commis Chef         House of Commons   \n",
       "4                        Recreation Works Supervisor      Forestry Commission   \n",
       "\n",
       "                                            location  salary closing_date  \\\n",
       "0                           Cardiff, Wales, CF14 3UZ  46,588   2024-03-05   \n",
       "1                                        Westminster  24,959   2024-05-19   \n",
       "2  East Midlands (England), East of England, Lond...  70,000   2024-02-26   \n",
       "3                                        Westminster  24,959   2024-05-19   \n",
       "4          Burley Office, Burley, Hampshire BH24 4HS  26,534   2024-01-14   \n",
       "\n",
       "      uid scraped_date  \n",
       "0  153376   2024-02-21  \n",
       "1  200324   2024-01-04  \n",
       "2   24711   2024-02-13  \n",
       "3  255755   2024-01-04  \n",
       "4  257501   2024-01-04  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import MySQLdb\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "load_dotenv()\n",
    "\n",
    "def database_query(sql_query):\n",
    "    try:\n",
    "        connection = MySQLdb.connect(\n",
    "        host=os.getenv(\"DATABASE_HOST\"),\n",
    "        user=os.getenv(\"DATABASE_USERNAME\"),\n",
    "        passwd=os.getenv(\"DATABASE_PASSWORD\"),\n",
    "        db=os.getenv(\"DATABASE\"),\n",
    "        autocommit=True,\n",
    "        # ssl_mode=\"VERIFY_iDENTITY\",\n",
    "        ssl={\"ca\": \"/etc/ssl/certs/ca-certificates.crt\"})\n",
    "    except:\n",
    "        connection = MySQLdb.connect(\n",
    "        host=os.environ[\"DATABASE_HOST\"],\n",
    "        user=os.environ[\"DATABASE_USERNAME\"],\n",
    "        passwd=os.environ[\"DATABASE_PASSWORD\"],\n",
    "        db=os.environ[\"DATABASE\"],\n",
    "        autocommit=True,\n",
    "        # ssl_mode=\"VERIFY_iDENTITY\",\n",
    "        ssl={\"ca\": \"/etc/ssl/certs/ca-certificates.crt\"})\n",
    "    try:\n",
    "        c = connection.cursor()\n",
    "        c.execute(sql_query)\n",
    "        results = c.fetchall()\n",
    "        return results\n",
    "    except MySQLdb.Error as e:\n",
    "        print(\"MySQL Error:\", e)\n",
    "    finally:\n",
    "        c.close()\n",
    "        connection.close()\n",
    "\n",
    "\n",
    "sql_query = '''\n",
    "\n",
    "select\n",
    "    title\n",
    "    ,department\n",
    "    ,location\n",
    "    ,salary\n",
    "    ,closing_date\n",
    "    ,uid\n",
    "    ,scraped_date\n",
    "from \n",
    "    all_time_listings\n",
    "\n",
    "'''\n",
    "\n",
    "df = pd.DataFrame(database_query(sql_query))\n",
    "df.columns = ['title', 'department', 'location', 'salary', 'closing_date', 'uid', 'scraped_date']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import ggplot, scale_fill_gradient, scale_color_continuous, scale_color_gradient, aes, geom_point, geom_col, geom_line, geom_histogram, geom_boxplot, facet_wrap, theme, element_text, element_blank, element_rect, element_line, labs, scale_x_continuous, scale_y_continuous, scale_fill_manual, scale_color_manual, scale_linetype_manual, scale_shape_manual, scale_size_manual, scale_alpha_manual, coord_flip, coord_cartesian, coord_fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot showing median salaries by department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/plotnine/ggplot.py:604: PlotnineWarning: Saving 20 x 10 in image.\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/plotnine/ggplot.py:605: PlotnineWarning: Filename: department_salary.png\n"
     ]
    }
   ],
   "source": [
    "df['salary_int'] = df['salary'].str.replace(',','')\n",
    "df['salary_int'] = df['salary_int'].astype(float)\n",
    "df['scraped_date_date'] = pd.to_datetime(df['scraped_date'])\n",
    "df['week_commencing'] = df['scraped_date_date'].dt.to_period('W').dt.start_time\n",
    "df['salary_int'].describe()\n",
    "daily_salary = df[['week_commencing','salary_int','department','location']].groupby(['week_commencing','salary_int','department','location']).mean().reset_index()\n",
    "department_salary = df.groupby('department').agg({'salary_int':'median','uid':'count'}).reset_index().sort_values('salary_int', ascending=False)\n",
    "department_salary.columns = ['department','salary_int','Number of Postings']\n",
    "\n",
    "# department_salary = pd.concat([department_salary.nlargest(5, 'salary_int').reset_index(),department_salary.nsmallest(5, 'salary_int').reset_index()], axis=0, ignore_index=True).sort_values('salary_int', ascending=False)\n",
    "\n",
    "plot = (\n",
    "    ggplot(department_salary, aes(x=\"reorder(department, salary_int, ascending=False)\", y='salary_int'\n",
    "                                    ,color='Number of Postings', fill='Number of Postings'\n",
    "                                   ))\n",
    "\n",
    "    + geom_col()\n",
    "    # + theme(legend_position='none')\n",
    "    + scale_color_gradient(limits=[10, 100], labels=['<10', '>100'], breaks=[10, 100])\n",
    "    + scale_fill_gradient(limits=[10, 100], labels=['<10', '>100'], breaks=[10, 100])\n",
    "    + labs(title=f\"Civil Service Departments Median Salary Comparison: {df['scraped_date_date'].dt.date.min()} to {df['scraped_date_date'].dt.date.max()}\"\n",
    "           , x='Department'\n",
    "           , y='Median Salary (£)'\n",
    "           , caption='Source: Civil Service Jobs (https://www.civilservicejobs.service.gov.uk/)')\n",
    "    + theme(axis_text_x=element_text(angle=90, face='bold'))\n",
    "    + theme(axis_text_x=element_text(size=6))\n",
    "    + theme(axis_text_y=element_text(size=6))\n",
    "    + theme(plot_caption=element_text(size=6, face='italic'))\n",
    "    + theme(plot_title=element_text(size=20, face='bold'))\n",
    ")\n",
    "\n",
    "plot.save(\"department_salary.png\", width=20, height=10, units='in', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA checks passed. Number of departments checked:  161\n"
     ]
    }
   ],
   "source": [
    "##department median salary QA\n",
    "\n",
    "pass_qa = True\n",
    "number_of_departments = 0\n",
    "def qa_check(df, department):\n",
    "    global pass_qa\n",
    "    global number_of_departments\n",
    "    department_median = df[df['department']==department]['salary_int'].values[0]\n",
    "    df_department = df[df['department']==department]\n",
    "    difference = department_median - df_department['salary_int'].describe().values[5]\n",
    "    if difference > 0:\n",
    "        print(f\"Variation in QA check for {department}\")\n",
    "        pass_qa = False\n",
    "    else:\n",
    "        number_of_departments += 1\n",
    "\n",
    "\n",
    "for i in df['department'].unique():\n",
    "    qa_check(department_salary, i)\n",
    "if pass_qa:\n",
    "    print(\"QA checks passed. Number of departments checked: \", number_of_departments)\n",
    "else:\n",
    "    print(\"QA checks failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See if we can pull number of posts out of the data as well to improve salary averages?\n",
    "Compare highest salaries with behvaiours to establish highest-value behaviours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_df = pd.DataFrame(database_query('select * from all_time_ad_qualities'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_df.columns = [\n",
    "        'uid', \n",
    "        'developing_self_and_others', \n",
    "        'leadership',\n",
    "        'making_effective_decisions',\n",
    "        'seeing_the_big_picture',\n",
    "        'managing_a_quality_service',\n",
    "        'working_together',\n",
    "        'communicating_and_influencing',\n",
    "        'changing_and_improving',\n",
    "        'delivering_at_pace',\n",
    "        'apply_at_advertisers_site',\n",
    "        'cv',\n",
    "        'personal_statement',\n",
    "        'reference_request',\n",
    "        'application_form',\n",
    "        'cover_letter',\n",
    "        'presentation',\n",
    "        'interview',\n",
    "        'portfolio',\n",
    "        'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>department</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>closing_date</th>\n",
       "      <th>uid</th>\n",
       "      <th>scraped_date</th>\n",
       "      <th>salary_int</th>\n",
       "      <th>scraped_date_date</th>\n",
       "      <th>week_commencing</th>\n",
       "      <th>...</th>\n",
       "      <th>apply_at_advertisers_site</th>\n",
       "      <th>cv</th>\n",
       "      <th>personal_statement</th>\n",
       "      <th>reference_request</th>\n",
       "      <th>application_form</th>\n",
       "      <th>cover_letter</th>\n",
       "      <th>presentation</th>\n",
       "      <th>interview</th>\n",
       "      <th>portfolio</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst - Corporate Performance</td>\n",
       "      <td>Companies House</td>\n",
       "      <td>Cardiff, Wales, CF14 3UZ</td>\n",
       "      <td>46,588</td>\n",
       "      <td>2024-03-05</td>\n",
       "      <td>153376</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>46588.0</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>2024-02-19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title       department  \\\n",
       "0  Senior Data Analyst - Corporate Performance   Companies House   \n",
       "\n",
       "                   location  salary closing_date     uid scraped_date  \\\n",
       "0  Cardiff, Wales, CF14 3UZ  46,588   2024-03-05  153376   2024-02-21   \n",
       "\n",
       "   salary_int scraped_date_date week_commencing  ...  \\\n",
       "0     46588.0        2024-02-21      2024-02-19  ...   \n",
       "\n",
       "   apply_at_advertisers_site   cv  personal_statement  reference_request  \\\n",
       "0                        0.0  1.0                 1.0                0.0   \n",
       "\n",
       "   application_form  cover_letter  presentation  interview  portfolio  test  \n",
       "0               0.0           0.0           1.0        1.0        0.0   0.0  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['uid'] = df['uid'].astype(int)\n",
    "application_df['uid'] = application_df['uid'].astype(int)\n",
    "combined_df = pd.merge(df, application_df, on='uid', how='left')\n",
    "combined_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2597/519122141.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "behaviours_df = combined_df[['department', 'week_commencing', 'salary_int',\n",
    "        'developing_self_and_others', \n",
    "        'leadership',\n",
    "        'making_effective_decisions',\n",
    "        'seeing_the_big_picture',\n",
    "        'managing_a_quality_service',\n",
    "        'working_together',\n",
    "        'communicating_and_influencing',\n",
    "        'changing_and_improving',\n",
    "        'delivering_at_pace']]\n",
    "\n",
    "def salary_bucket_func(salary_int):\n",
    "        bucket = '£90k+'\n",
    "        salary_bucket_dict = {\n",
    "                90000: '£70k-£90k'\n",
    "                , 70000: '£50k-£70k'\n",
    "                , 50000: '£30k-£50k'\n",
    "                , 30000: '<£30k'}\n",
    "        try:\n",
    "                for salary in salary_bucket_dict.keys():\n",
    "                        if salary_int <= salary:\n",
    "                                bucket = salary_bucket_dict[salary]\n",
    "                                \n",
    "\n",
    "                \n",
    "        except:\n",
    "                bucket = 'bad entry'\n",
    "        return bucket\n",
    "\n",
    "salary_bucket_func_vectorised = np.vectorize(salary_bucket_func)\n",
    "behaviours_df['salary_bucket'] = salary_bucket_func_vectorised(behaviours_df['salary_int'])\n",
    "\n",
    "grouped_behaviours = behaviours_df[['department'\n",
    "                                    , 'week_commencing'\n",
    "                                    , 'salary_bucket'\n",
    "                                    , 'developing_self_and_others'\n",
    "                                    , 'leadership'\n",
    "                                    , 'making_effective_decisions'\n",
    "                                    , 'seeing_the_big_picture'\n",
    "                                    , 'managing_a_quality_service'\n",
    "                                    , 'working_together'\n",
    "                                    , 'communicating_and_influencing'\n",
    "                                    , 'changing_and_improving'\n",
    "                                    , 'delivering_at_pace']].groupby(['department','week_commencing','salary_bucket']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/plotnine/ggplot.py:604: PlotnineWarning: Saving 20 x 10 in image.\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/plotnine/ggplot.py:605: PlotnineWarning: Filename: behaviour_plot.png\n"
     ]
    }
   ],
   "source": [
    "melted_behaviours = pd.melt(grouped_behaviours, id_vars=['department', 'week_commencing', 'salary_bucket'], value_vars=['developing_self_and_others', 'leadership', 'making_effective_decisions', 'seeing_the_big_picture', 'managing_a_quality_service', 'working_together', 'communicating_and_influencing', 'changing_and_improving', 'delivering_at_pace'])\n",
    "melted_behaviours.columns = ['department', 'week_commencing', 'salary_bucket', 'behaviour', 'count']\n",
    "\n",
    "melted_behaviours = melted_behaviours[['salary_bucket', 'behaviour', 'count']].groupby(['salary_bucket', 'behaviour']).sum().reset_index()\n",
    "\n",
    "def behaviour_cleaner(behaviour):\n",
    "    behaviour_dict = {\n",
    "        'developing_self_and_others': 'Developing Self and Others'\n",
    "        , 'leadership': 'Leadership'\n",
    "        , 'making_effective_decisions': 'Making Effective Decisions'\n",
    "        , 'seeing_the_big_picture': 'Seeing the Big Picture'\n",
    "        , 'managing_a_quality_service': 'Managing a Quality Service'\n",
    "        , 'working_together': 'Working Together'\n",
    "        , 'communicating_and_influencing': 'Communicating and Influencing'\n",
    "        , 'changing_and_improving': 'Changing and Improving'\n",
    "        , 'delivering_at_pace': 'Delivering at Pace'\n",
    "    }\n",
    "    return behaviour_dict[behaviour]\n",
    "\n",
    "melted_behaviours['behaviour'] = melted_behaviours['behaviour'].apply(behaviour_cleaner)\n",
    "\n",
    "df['salary_bucket'] = salary_bucket_func_vectorised(df['salary_int'])\n",
    "df = df[df['salary_bucket']!='bad entry']\n",
    "total_bucket_counts = df['salary_bucket'].value_counts().reset_index()\n",
    "total_bucket_counts.columns = ['salary_bucket', 'total_count']\n",
    "melted_behaviours['cum_sum'] = (melted_behaviours.groupby(['salary_bucket'])['count'].transform('max'))\n",
    "melted_behaviours = pd.merge(melted_behaviours, total_bucket_counts, how='left')\n",
    "melted_behaviours['percentage'] = (melted_behaviours['count'] / melted_behaviours['total_count']) * 100\n",
    "\n",
    "behaviour_plot = (\n",
    "    ggplot(melted_behaviours, aes(x='behaviour', y='percentage', color='behaviour', fill='behaviour'))\n",
    "    + geom_col()\n",
    "    + facet_wrap('salary_bucket', nrow=1)\n",
    "    + labs(title='Behaviours Requested by Salary Bucket'\n",
    "           , x=''\n",
    "           , y='Percentage of Postings Mentioning Behaviour (%)'\n",
    "           , caption='Source: Civil Service Jobs (https://www.civilservicejobs.service.gov.uk/)')\n",
    "    + theme(axis_title_y=element_text(size='14'))\n",
    "    # + theme(legend_position='none')\n",
    "    + theme(axis_text_x=element_text(color='white'))\n",
    "    + theme(axis_ticks_x=element_text(color='white'))\n",
    "    + theme(legend_title=element_blank())\n",
    "    #custom fill colours\n",
    "    + scale_fill_manual(values=['#87CEEB', '#FFD300', '#FC6A03', '#FFC0CB', '#7E38B7', '#378805', '#1E2F97', '#7c3f00', '#2f2f2f'])\n",
    "    + scale_color_manual(values=['#87CEEB', '#FFD300', '#FC6A03', '#FFC0CB', '#7E38B7', '#378805', '#1E2F97', '#7c3f00', '#2f2f2f'])\n",
    ")\n",
    "\n",
    "behaviour_plot.save(\"behaviour_plot.png\", width=20, height=10, units='in', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA check passed for Changing and Improving, total found in input dataframe: 2264, total found in melted dataframe: 2264.0\n",
      "QA check passed for Communicating and Influencing, total found in input dataframe: 2449, total found in melted dataframe: 2449.0\n",
      "QA check passed for Delivering at Pace, total found in input dataframe: 2682, total found in melted dataframe: 2682.0\n",
      "QA check failed for Developing Self and Others, total found in input dataframe: 2134, total found in melted dataframe: 2132.0\n",
      "QA check passed for Leadership, total found in input dataframe: 2696, total found in melted dataframe: 2696.0\n",
      "QA check passed for Making Effective Decisions, total found in input dataframe: 2108, total found in melted dataframe: 2108.0\n",
      "QA check passed for Managing a Quality Service, total found in input dataframe: 2395, total found in melted dataframe: 2395.0\n",
      "QA check passed for Seeing the Big Picture, total found in input dataframe: 2223, total found in melted dataframe: 2223.0\n",
      "QA check passed for Working Together, total found in input dataframe: 2280, total found in melted dataframe: 2280.0\n"
     ]
    }
   ],
   "source": [
    "behaviour_qa_pass = True\n",
    "behaviours = melted_behaviours['behaviour'].unique()\n",
    "bad_uids = []\n",
    "def behaviour_qa(input_df, behaviour, melted_df, chart_df):\n",
    "    global behaviour_qa_pass\n",
    "    global bad_uids\n",
    "\n",
    "\n",
    "    behaviour_swap_back  = {\n",
    "        'Developing Self and Others': 'developing_self_and_others'\n",
    "        , 'Leadership': 'leadership'\n",
    "        , 'Making Effective Decisions': 'making_effective_decisions'\n",
    "        , 'Seeing the Big Picture': 'seeing_the_big_picture'\n",
    "        , 'Managing a Quality Service': 'managing_a_quality_service'\n",
    "        , 'Working Together': 'working_together'\n",
    "        , 'Communicating and Influencing': 'communicating_and_influencing'\n",
    "        , 'Changing and Improving': 'changing_and_improving'\n",
    "        , 'Delivering at Pace': 'delivering_at_pace'\n",
    "    }\n",
    "    lower_behaviour = behaviour_swap_back[behaviour]    \n",
    "    melted_df = melted_df[melted_df[lower_behaviour]==1][['uid', lower_behaviour]].sort_values('uid').reset_index(drop=True)\n",
    "    \n",
    "\n",
    "    total_found = input_df[lower_behaviour].sum()\n",
    "\n",
    "    input_beheaviour_uids = input_df[input_df[lower_behaviour]==1]\n",
    "    input_beheaviour_uids = input_beheaviour_uids[['uid', lower_behaviour]].sort_values('uid').reset_index(drop=True)\n",
    "    melted_total_found = melted_df[lower_behaviour].sum()\n",
    "    melted_df[lower_behaviour] = melted_df[lower_behaviour].astype(int)\n",
    "    processed_uids = melted_df['uid'].values\n",
    "    original_uids = input_beheaviour_uids['uid'].values\n",
    "    for i in original_uids:\n",
    "        if i not in processed_uids:\n",
    "            # print(f\"QA check failed for {behaviour}, {i} not found in melted dataframe\")\n",
    "            bad_uids.append(i)\n",
    "            behaviour_qa_pass = False\n",
    "    \n",
    "\n",
    "    chart_df = chart_df[chart_df['behaviour']==behaviour]\n",
    "    chart_df_total = chart_df['count'].sum()\n",
    "    if total_found != chart_df_total:\n",
    "        print(f\"QA check failed for {behaviour}, total found in input dataframe: {total_found}, total found in melted dataframe: {melted_total_found}\")\n",
    "        behaviour_qa_pass = False\n",
    "    else:\n",
    "        behaviour_qa_pass = True\n",
    "        print(f\"QA check passed for {behaviour}, total found in input dataframe: {total_found}, total found in melted dataframe: {melted_total_found}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "for behaviour in behaviours:\n",
    "    behaviour_qa(application_df, behaviour, combined_df, melted_behaviours)    \n",
    "if behaviour_qa_pass == False:\n",
    "    print(\"QA checks failed, these are the mismatched uids: \", bad_uids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'contains'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2597/565915349.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0muids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0manalyst_uids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muids_filtered_on_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'analy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0muids_filtered_on_salary_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msalary_range\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'salary_int'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0msalary_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'salary_int'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0msalary_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2597/565915349.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(df, title)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0muids_filtered_on_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0muids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0muids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6292\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6293\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6294\u001b[0m         ):\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6296\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'contains'"
     ]
    }
   ],
   "source": [
    "#need to debug this function to return uids where df['title'] contains any of the words in the list; won't take long but will need to pick up later \n",
    "\n",
    "def uids_filtered_on_title(df, title: list):\n",
    "    uids = []\n",
    "    df['title'] = df['title'].str.lower()\n",
    "    for i in title:\n",
    "        uids += df[df['title'].str.contains(i)]['uid'].values.tolist()\n",
    "    return set(uids)\n",
    "\n",
    "analyst_uids = uids_filtered_on_title(df, ['data', 'analy'])\n",
    "\n",
    "def uids_filtered_on_salary_int(df, salary_range: list):\n",
    "    return df[df['salary_int']>=salary_range[0] and df['salary_int'] <= salary_range[1]]['uid']\n",
    "\n",
    "g7_g6_uids = uids_filtered_on_salary_int(df, [50000, 70000])\n",
    "\n",
    "analyst_application_df = application_df[application_df['uid'].isin(analyst_uids)]\n",
    "g7_analyst_application_df = application_df[application_df['uid'].isin(g7_g6_uids) & application_df['uid'].isin(analyst_uids)]\n",
    "\n",
    "analyst_application_df['post_type'] = 'analyst_posts'\n",
    "g7_analyst_application_df['post_type'] = 'g7_analyst_posts'\n",
    "application_df['post_type'] = 'all_posts'\n",
    "\n",
    "def application_process_prep(application_df, posting_type):\n",
    "\n",
    "    application_process_df = application_df[[\n",
    "            'uid', \n",
    "            'apply_at_advertisers_site',\n",
    "            'cv',\n",
    "            'personal_statement',\n",
    "            'reference_request',\n",
    "            'application_form',\n",
    "            'cover_letter',\n",
    "            'presentation',\n",
    "            'interview',\n",
    "            'portfolio',\n",
    "            'test']]\n",
    "\n",
    "    melted_application_process_df = pd.melt(application_process_df, id_vars=['uid'], value_vars=['apply_at_advertisers_site', 'cv', 'personal_statement', 'reference_request', 'application_form', 'cover_letter', 'presentation', 'interview', 'portfolio', 'test'])\n",
    "    melted_application_process_df.columns = ['uid', 'application_process', 'appearances']\n",
    "    melted_application_process_df = melted_application_process_df[['application_process', 'appearances']]\n",
    "    melted_application_process_df = melted_application_process_df.groupby('application_process').sum().reset_index()\n",
    "\n",
    "    def application_process_cleaner(application_process):\n",
    "        application_process_dict = {\n",
    "            'apply_at_advertisers_site': 'Apply at Advertisers Site'\n",
    "            , 'cv': 'CV'\n",
    "            , 'personal_statement': 'Personal Statement'\n",
    "            , 'reference_request': 'Reference Request'\n",
    "            , 'application_form': 'Application Form'\n",
    "            , 'cover_letter': 'Cover Letter'\n",
    "            , 'presentation': 'Presentation'\n",
    "            , 'interview': 'Interview'\n",
    "            , 'portfolio': 'Portfolio'\n",
    "            , 'test': 'Online Test'\n",
    "        }\n",
    "        return application_process_dict[application_process]\n",
    "\n",
    "    melted_application_process_df['Application Process'] = melted_application_process_df['application_process'].apply(application_process_cleaner)\n",
    "    melted_application_process_df['posting_type'] = posting_type\n",
    "    return melted_application_process_df\n",
    "\n",
    "from plotnine import geom_bar\n",
    "\n",
    "analyst_application_process_df = application_process_prep(analyst_application_df, 'analyst_posts')\n",
    "g7_analyst_application_process_df = application_process_prep(g7_analyst_application_df, 'g7_analyst_posts')\n",
    "all_posts_application_process_df = application_process_prep(application_df, 'all_posts')\n",
    "\n",
    "\n",
    "combined_application_process_df = pd.concat([analyst_application_process_df, g7_analyst_application_process_df, all_posts_application_process_df], axis=0, ignore_index=True)\n",
    "\n",
    "application_process_plot = (\n",
    "\n",
    "    ggplot(combined_application_process_df, aes(y='appearances', x='Application Process', fill='Application Process'))\n",
    "    + geom_col()\n",
    "    + facet_wrap('posting_type', nrow=1)\n",
    "    + labs(title='Most Common Application Elements'\n",
    "           , y='Job Postings Mentioning Element'\n",
    "           , caption='Source: Civil Service Jobs (https://www.civilservicejobs.service.gov.uk/)')\n",
    "    + theme(axis_text_y=element_text(face='bold'))\n",
    "    #remove x axis text\n",
    "    + theme(axis_text_x=element_text(color='white'))\n",
    "    + theme(axis_ticks_x=element_text(color='white'))\n",
    "    + theme(axis_text_y=element_text(color='white'))\n",
    "    + theme(axis_ticks_y=element_text(color='white'))\n",
    ")\n",
    "\n",
    "application_process_plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
